# 📝 深度学习/实习学习日志 · 第7天

**日期**：2025年9月16日
**主题**：超参数与训练流程复盘 + ReLU、XOR、注意力、低秩与模型“随机性”速记

---

## 📌 今天学/记录到的要点（简短明了）

* **超参数是训练的“航海图”**：学习率决定步幅，batch 控制噪声和显存，epoch 控制训练时长。实战里先找 lr，再定 batch，大多用 early-stop 控制 epoch。
* **训练四步（程序员视角）**：`forward → loss → backward → optimizer.step`，每一步要配合好梯度清零（zero\_grad）与梯度裁剪（必要时）。
* **ReLU 的简单直觉**：把负信号全部拉扯成 0，正信号直接放行——因此计算简单、梯度稳定。要注意“死 ReLU”（学习率太大会把一片神经元永远推为 0）。
* **XOR 的教学意义**：单层线性模型学不了 XOR，说明线性可分与非线性激活的必要性；这是深度/非线性价值的最简证明。
* **注意力 Q/K/V 的直观比喻**：Q 是问题（我在找什么），K 是提示（哪个位置可能相关），V 是内容（真正要拿的信息）。多头注意力 = 多个不同视角并行观察并合并，提升表达力。
* **低秩变换（LoRA 思路）**：把大矩阵分解成小矩阵乘积（`W ≈ U V`），节省参数与运算，同时保留主方向的信息，适合微调与模型压缩。
* **LLM 的“随机性”来源分两类**：

  1. 有意采样（temperature/top-k/top-p）使输出多样；
  2. 工程不确定性（浮点、并行、实现差异）在不同运行间产生微小差别。想完全确定通常要牺牲一部分性能或工程复杂度。

---

## 🧠 小结（三句话）

1. **先把训练流程跑通再调参**：先保证 forward/backward/step 没 bug，再用 lr-finder、验证曲线来调整超参。
2. **把问题想成“大量 MAC + 数据搬运”**：把能复用的数据放近算力（shared/registers），让算子（比如卷积、FIR）变成矩阵乘加或 tiled 形式。
3. **理论与工程并重**：知道为什么（XOR、ReLU、低秩）重要，同时要用 profiler/工具确认真瓶颈（bandwidth vs FLOPS）。

---

## ❓ 今日自问自答（实习式反思）

**Q：先调哪个超参？**
A：先调学习率；可用 lr-finder 找候选起点；batch 受显存制约，若显存允许再调大。

**Q：什么时候考虑用低秩/LoRA？**
A：当模型太大、微调成本高，且要保留原模型的大部分参数时，用 LoRA 可以用很小的参数量取得不错效果。

**Q：如何判断是内存瓶颈还是算力瓶颈？**
A：用 profiler（Nsight / nvprof / PyTorch profiler）。若 GPU 利用率低但内存带宽占满，通常是 memory-bound；反之若计算单元满载则是 compute-bound。

---

## 🔜 明天/下一步计划（可量化）

1. 在小数据集上跑一个完整训练循环（PyTorch）：记录训练/验证 loss 曲线并保存 checkpoint。
2. 做一次 lr-finder（画 loss vs lr），选一个 lr 并用 cosine warmup 试验。
3. 实验 ReLU vs GELU 在同模型同 lr 下的训练差异（记录收敛速度与最终验证分数）。

---

## 备注

写日志时别只记结论，尽量写下**做了什么命令/代码片段**和**测到的曲线图**，以后回看能省大量时间。今天学的概念都是工具箱里的“常用螺丝刀”，下次做实验时把它们实际拿出来用一遍。
