# 📝 深度学习学习日志 · 第3天

**日期**：2025年9月11日
**主题**：超参数（learning rate / batch / epoch）与训练流程（前向 → 损失 → 反向）＋ ReLU、本质性概念串讲（XOR、注意力、低秩变换、LLM 的“随机性”）

---

## 📌 今天学了什么

* **什么是超参数？**
  超参数就是在训练前要定下来的“控制开关”——不是模型里要学的参数（比如权重），而是我们给训练过程的设置。像学习率、每批数据大小（batch）、训练轮数（epoch）都属于超参数。

* **学习率（learning rate）为什么重要？**
  学习率决定每次用梯度更新参数时“走多远”。太大可能越过最优点发散，太小则收敛很慢甚至卡在局部最优。常见经验值：用 Adam 时常从 `1e-3` 开始，SGD 常从 `1e-2 ~ 1e-1` 试起（仅供参考）。

* **batch（小批量）和 epoch（轮数）是什么？**

  * batch：每一步用多少训练样本算梯度。小 batch 噪声更大但更节省显存；大 batch 梯度更稳定但需要更多显存。常见选项：32、64、128。
  * epoch：把全部训练数据看作一轮，epoch 是完整遍历数据的次数。epoch 太少欠拟合，太多可能过拟合。

* **这些超参数能否自动优化？**
  能在一定程度上自动化：有学习率调度器（把 lr 随训练自动调整）、有“学习率查找器”能帮你找到合适的起始 lr，也有自动调参库（像 Optuna、Ray Tune）做网格/随机/贝叶斯搜索。但关键还是要用验证集看效果，人的直觉+观察常常很有用。

* **前向传播、算损失、反向传播（训练的四步）**

  1. **前向（forward）**：输入 → 网络 → 得到输出分数/概率。
  2. **算损失（loss）**：用交叉熵等衡量预测和真实标签的差距。
  3. **反向（backward）**：把损失对每个参数的导数算出来（梯度），逐层传回去。
  4. **更新参数（optimizer.step）**：用梯度乘以学习率，调整权重；然后清零梯度准备下一步。

* **ReLU 的原理和优势**
  ReLU：`f(x) = max(0, x)`。可以想成一个“单向水闸”：正数可以通过（原样输出），负数被切断（输出 0）。好处是简单、计算快、能缓解梯度消失（相比 sigmoid/tanh），训练中通常比这些老激活更稳定、更容易收敛。

* **XOR（异或）为什么重要**
  XOR：相同返回 0，不同返回 1。单层感知机（线性模型）没法表示 XOR，说明问题是“非线性可分”的。需要多层和非线性激活才能学会。这是为什么“深度”和“非线性”很关键的直观例子。

* **深度学习输出的“随机性”**
  理论上给定同一个输入、同一个确定性推理方式，模型的概率分布是确定的。但实际会看到“不同输出”有两类原因：

  1. **有意采样**（temperature、top-k、top-p 等）会让输出随机；
  2. **工程上的不确定性**——比如浮点舍入、并行化、batch 切分策略，会让即使关闭采样也出现微小差异。有研究发现这会导致推理不完全确定，但改成全确定性的内核会牺牲效率。

* **单头 vs 多头注意力 & Q/K/V 的直观意义**

  * 单头：从一个“视角”看上下文；多头：多个独立视角同时看（好比用几种放大镜看句子），最后把信息合并，表达更丰富。
  * Q（Query）像“我在找什么”；K（Key）像“每个位置的标签”；V（Value）是“真正的信息内容”。注意力就是算 Q 和 K 的相关性，然后按权重取加权的 V。

* **权重（weights）本质上是什么**
  大多是矩阵（线性层、注意力里的投影），卷积可以看成特殊形状的矩阵运算。训练的目标就是把这些矩阵调到合适的值。

* **低秩变换（Low-rank transformation），简单比喻**
  把一个很大的矩阵 `W` 用两个小矩阵 `U`、`V` 近似（`W ≈ U V`）。等于先把信息压缩到低维，再恢复。好处：参数少、算得快、防止过拟合。应用举例：模型压缩、LoRA 微调、降噪、信号压缩（像 JPEG 的思想一样）。数学上“低秩”就是矩阵只有少数独立方向，丢掉小的奇异值只保留主要信息。

---

## ❓ Q & A

**Q：为什么 lr、batch、epoch 被叫超参数？**
A：因为它们不是模型要学的权重，而是训练过程的配置，会影响训练路线和结果，但不能通过一次标准反向传播内自动学到。

**Q：如何调这些超参数？给步骤/策略**

1. 先定好验证集（用于监控，不用看测试集）。
2. 学习率优先调：用 lr-finder（或试一系列指数级 lr，比如 `1e-5,1e-4,1e-3,1e-2`），找那段 loss 快速下降的 lr。
3. Batch 大小按显存和收敛稳定性取舍（常试 32/64/128）。
4. Epoch 用早停（early stopping）和验证损失判断，不要盲目设很大。
5. 如果想系统化：用随机搜索/贝叶斯优化（Optuna 等）来自动化多参数组合；常配合学习率调度器（ReduceOnPlateau、cosine annealing、warmup 等）。
6. 记录实验（最好写 README 或表格），每次只改一两个参数，方便分析。

**Q：这些能完全自动化吗？**
A：有工具能大幅自动化，但也不是“放手就行”的黑盒：选目标函数、搜参范围、资源预算、衡量指标都需要人来定。自动化能节省工作量，但人工经验仍然重要。

---

## 🔜 下一步计划

1. 在本地用一个小数据集跑一个完整训练循环（PyTorch）：实现 forward → loss → backward → optimizer.step。记录训练/验证曲线。
2. 做一次简单的学习率寻找实验（试不同 lr，画 loss vs lr），选一个合适的 lr 再训练。
3. 比较 ReLU 和 sigmoid/tanh 的训练速度与训练曲线（对比同一模型、同一 lr、同一 batch）。
