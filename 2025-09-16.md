# 📝 深度学习学习日志 · 第6天

**日期**：2025年9月16日
**主题**：超参数（学习率 / 批量 / 轮数）与训练流程（前向 → 损失 → 反向）＋ ReLU 与几个核心概念（XOR、注意力、低秩、模型输出差异）

---

## 今天学到了什么

### 一、超参数是什么？

超参数就是训练前我们要先定下来的“训练规则”，它们不是模型自己学的东西。例如：学习率（learning rate）、每次喂给模型的数据条数（batch）、完整看完一遍数据的次数（epoch）。这些会直接影响训练快慢和效果。

### 二、学习率（learning rate）

学习率决定每次根据梯度调整参数时的步子有多大。

* 步子太大：可能跳过最优点，训练发散。
* 步子太小：收敛很慢，需要更多时间。
  经验上不同优化器有常用起点，但要通过实验调整。

### 三、batch（批）和 epoch（轮）

* **batch**：一次喂入模型的样本数。小批量更省显存、噪声大；大批量更稳定、但占用显存。
* **epoch**：把全部训练数据看作一圈，完整学一遍算一个 epoch。通常训练多轮直到验证集不再提升为止。

### 四、能不能自动调这些超参数？

可以部分自动化（用学习率调度器、自动调参工具），但最好还是结合验证集观察结果并人工判断。

### 五、训练的基本流程

1. **前向（forward）**：输入数据 → 模型 → 得到预测。
2. **计算损失（loss）**：用一个公式衡量预测和真实值的差距。
3. **反向（backward）**：计算各参数对损失的影响（梯度）。
4. **更新参数（optimizer.step）**：按梯度和学习率调整参数；清空梯度准备下一步。

### 六、ReLU 是什么，为什么常用

ReLU 的公式很简单：大于 0 的数原样输出，小于等于 0 的数变成 0。
优点：计算快、在深层网络里不容易出现“梯度消失”，训练更稳健。

### 七、XOR 问题为什么重要（直观）

XOR 是一个简单例子：单层的线性模型学不来它，说明我们需要**非线性**（比如 ReLU）和**多层结构**来表示复杂关系。这个例子是理解“为什么要深度和非线性”的入门直观教材。

### 八、深度学习输出看起来“有随机性”的原因

输出真正随机的场景是我们故意采样（temperature、top-k）。但即使不采样，也可能出现差异——原因主要是数值计算上的差别（浮点舍入、不同的并行实现、不同 batch 大小导致内核选择不同实现等）。工程上看起来像“不确定”，但本质上很多是实现细节造成的可重复性差异。

### 九、注意力（Attention）里 Q、K、V 的直观含义

* Q（Query）：问句——“我现在需要什么信息？”
* K（Key）：每个位置的标签或标记，表示“这里有什么特点”。
* V（Value）：真正的信息内容。
  注意力就是计算 Q 与每个 K 的相似度，再按权重把对应的 V 加起来得到答案。多头注意力就是同时用多个不同“视角”去看一句话，能捕获更多不同的关系。

### 十、权重本质上是啥？

权重就是模型要学的矩阵或向量，把输入映射成输出。训练的目标就是把这些矩阵调成合适的数，使模型能做出正确预测。

### 十一、低秩变换（Low-rank）

把一个大矩阵用两个小矩阵近似（先压缩再还原），相当于只保留主要信息方向。优点是参数少、计算更快，经常用于模型压缩或高效微调（比如 LoRA）。

---

## 简单问答

**Q：为什么把这些叫超参数？**
A：因为它们不是模型自己学的，而是我们训练前设定的控制项，会影响训练过程和结果。

**Q：怎样调这些超参数？**
A：先固定验证集；优先调学习率（找能让 loss 快速下降的起点），然后按显存调整 batch；用 early stopping 避免过拟合。也可以用自动化工具做搜索，但最好每次只改一两个参数看效果。

**Q：ReLU 真那么好么？**
A：在大多数任务里，ReLU 简单高效，比老式 sigmoid、tanh 更容易训练。但也有它的缺点（例如神经元“死亡”问题），需要根据任务选择。

---

## 下一步计划

1. 在本地跑一个小模型（比如一个两层的全连接网络）完成一次训练流程，画出训练/验证 loss 曲线。
2. 做一次学习率实验：试几个不同的 lr，比较收敛速度和最终效果。
3. 用同一数据和网络分别试 ReLU 和 sigmoid，比较训练速度和最终结果。
4. 做一个小实验：用 batch=1 与 batch=8 分别推理同一输入，观察输出差异（理解 batch 不变性的问题）。
